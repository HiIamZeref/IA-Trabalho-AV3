{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEhkPKsMkH77"
      },
      "source": [
        "## Imports principais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YOyBeEB4kHeE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMtVFAr9hmCI"
      },
      "source": [
        "## Implementação dos modelos para classificação\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT3ddKynmSGT"
      },
      "source": [
        "### Perceptron simples classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IR6AAwY5mU_-",
        "outputId": "c2beff1f-a98d-418c-9d19-cd92d5bc5b25"
      },
      "outputs": [],
      "source": [
        "def perceptron_simples_classification_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do perceptron simples voltado para classificação.\n",
        "    Retorna os pesos finais, a acurácia de treino média, a acurácia de teste média, \n",
        "    e as listas de acurácia de treino e teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar a acurácia\n",
        "    acuracia_treino_list = []\n",
        "    acuracia_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        acertos_treino = 0\n",
        "\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            erro = y_true - y_pred\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_treino += 1\n",
        "\n",
        "            # Atualizando os pesos\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando a acurácia de treino\n",
        "        acuracia_treino = acertos_treino / len(X_train)\n",
        "        acuracia_treino_list.append(acuracia_treino)\n",
        "\n",
        "        # Fase de teste\n",
        "        acertos_teste = 0\n",
        "        for x, y_true in zip(X_test, y_test):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_teste += 1\n",
        "\n",
        "        # Calculando e armazenando a acurácia de teste\n",
        "        acuracia_teste = acertos_teste / len(X_test)\n",
        "        acuracia_teste_list.append(acuracia_teste)\n",
        "\n",
        "    # Calculando a acurácia média de treino e teste\n",
        "    acuracia_treino_media = np.mean(acuracia_treino_list)\n",
        "    acuracia_teste_media = np.mean(acuracia_teste_list)\n",
        "\n",
        "    return w, acuracia_treino_media, acuracia_teste_media, acuracia_treino_list, acuracia_teste_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i45l-ZI3KWQg"
      },
      "source": [
        "### ADALINE classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ3lLcnLKbOl",
        "outputId": "6773c24a-a92a-4df8-c1d9-cdd03c8099d0"
      },
      "outputs": [],
      "source": [
        "def adaline_classification_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do ADALINE voltado para classificação.\n",
        "    Retorna os pesos finais, a acurácia de treino média, a acurácia de teste média,\n",
        "    e as listas de acurácia de treino e teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar a acurácia\n",
        "    acuracia_treino_list = []\n",
        "    acuracia_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        acertos_treino = 0\n",
        "\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            erro = y_true - u\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_treino += 1\n",
        "\n",
        "            # Atualizando os pesos com a regra de atualização do ADALINE\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando a acurácia de treino\n",
        "        acuracia_treino = acertos_treino / len(X_train)\n",
        "        acuracia_treino_list.append(acuracia_treino)\n",
        "\n",
        "        # Fase de teste\n",
        "        acertos_teste = 0\n",
        "        for x, y_true in zip(X_test, y_test):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_teste += 1\n",
        "\n",
        "        # Calculando e armazenando a acurácia de teste\n",
        "        acuracia_teste = acertos_teste / len(X_test)\n",
        "        acuracia_teste_list.append(acuracia_teste)\n",
        "\n",
        "    # Calculando a acurácia média de treino e teste\n",
        "    acuracia_treino_media = np.mean(acuracia_treino_list)\n",
        "    acuracia_teste_media = np.mean(acuracia_teste_list)\n",
        "\n",
        "    return w, acuracia_treino_media, acuracia_teste_media, acuracia_treino_list, acuracia_teste_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGDnoZERwcq8"
      },
      "source": [
        "### Perceptron de múltiplas camadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq-Er75bwb6M",
        "outputId": "16dd9925-c126-432d-a920-b9f7866b0c8d"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def mlp_classification_training(X_test,\n",
        "                                y_test,\n",
        "                                X_train,\n",
        "                                y_train, \n",
        "                                lr, \n",
        "                                epochs=100, \n",
        "                                hidden_neurons=8):\n",
        "    '''\n",
        "    Treinamento de um perceptron de múltiplas camadas voltado para classificação.\n",
        "    Retorna os pesos finais, a acurácia de treino média, a acurácia de teste média,\n",
        "    e as listas de acurácia de treino e teste por época.\n",
        "    '''\n",
        "\n",
        "    # Inicializando os pesos\n",
        "    input_neurons = X_train.shape[1]\n",
        "    output_neurons = len(np.unique(y_train))  # Número de classes\n",
        "\n",
        "    # Pesos e bias entre camada de entrada e oculta\n",
        "    W1 = np.random.randn(input_neurons, hidden_neurons)\n",
        "    b1 = np.zeros((1, hidden_neurons))\n",
        "\n",
        "    # Pesos e bias entre camada oculta e saída\n",
        "    W2 = np.random.randn(hidden_neurons, output_neurons)\n",
        "    b2 = np.zeros((1, output_neurons))\n",
        "\n",
        "    # Listas para armazenar a acurácia\n",
        "    acuracia_treino_list = []\n",
        "    acuracia_teste_list = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Forward pass\n",
        "        hidden_input = np.dot(X_train, W1) + b1\n",
        "        hidden_output = relu(hidden_input)\n",
        "\n",
        "        final_input = np.dot(hidden_output, W2) + b2\n",
        "        final_output = sigmoid(final_input)\n",
        "\n",
        "        # Calculando erro\n",
        "        y_train_one_hot = np.eye(output_neurons)[y_train]  # Convertendo para one-hot encoding\n",
        "        error = y_train_one_hot - final_output\n",
        "\n",
        "        # Backward pass\n",
        "        d_output = error * sigmoid_derivative(final_output)\n",
        "        error_hidden_layer = d_output.dot(W2.T)\n",
        "        d_hidden_layer = error_hidden_layer * relu_derivative(hidden_output)\n",
        "\n",
        "        # Atualização dos pesos e bias\n",
        "        W2 += hidden_output.T.dot(d_output) * lr\n",
        "        b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "        W1 += X_train.T.dot(d_hidden_layer) * lr\n",
        "        b1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
        "\n",
        "        # Calculando acurácia de treino\n",
        "        train_predictions = np.argmax(final_output, axis=1)\n",
        "        acertos_treino = np.sum(train_predictions == y_train)\n",
        "        acuracia_treino = acertos_treino / len(y_train)\n",
        "        acuracia_treino_list.append(acuracia_treino)\n",
        "\n",
        "        # Forward pass para teste\n",
        "        hidden_input_test = np.dot(X_test, W1) + b1\n",
        "        hidden_output_test = relu(hidden_input_test)\n",
        "\n",
        "        final_input_test = np.dot(hidden_output_test, W2) + b2\n",
        "        final_output_test = sigmoid(final_input_test)\n",
        "\n",
        "        # Calculando acurácia de teste\n",
        "        test_predictions = np.argmax(final_output_test, axis=1)\n",
        "        acertos_teste = np.sum(test_predictions == y_test)\n",
        "        acuracia_teste = acertos_teste / len(y_test)\n",
        "        acuracia_teste_list.append(acuracia_teste)\n",
        "\n",
        "    # Calculando a acurácia média de treino e teste\n",
        "    acuracia_treino_media = np.mean(acuracia_treino_list)\n",
        "    acuracia_teste_media = np.mean(acuracia_teste_list)\n",
        "\n",
        "    return (W1, b1, W2, b2), acuracia_treino_media, acuracia_teste_media, acuracia_treino_list, acuracia_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EBTJ4VN0JIk"
      },
      "source": [
        "## Implementação modelos regressão\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OLxHHjKUHqL"
      },
      "source": [
        "### Perceptron Simples para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMSU7mHz0Mnj",
        "outputId": "ae939e4f-d9ac-4b50-807d-4fb380043cf7"
      },
      "outputs": [],
      "source": [
        "def perceptron_simples_regression_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do perceptron simples voltado para regressão.\n",
        "    Retorna os pesos finais, o erro quadrático médio de treino e de teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar o MSE\n",
        "    mse_treino_list = []\n",
        "    mse_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            y_pred = np.dot(x, w)\n",
        "            erro = y_true - y_pred\n",
        "\n",
        "            # Atualizando os pesos\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando o MSE de treino\n",
        "        y_train_pred = np.dot(X_train, w)\n",
        "        mse_treino = np.mean((y_train - y_train_pred) ** 2)\n",
        "        mse_treino_list.append(mse_treino)\n",
        "\n",
        "        # Calculando e armazenando o MSE de teste\n",
        "        y_test_pred = np.dot(X_test, w)\n",
        "        mse_teste = np.mean((y_test - y_test_pred) ** 2)\n",
        "        mse_teste_list.append(mse_teste)\n",
        "\n",
        "    mse_treino_media = np.mean(mse_treino_list)\n",
        "    mse_teste_media = np.mean(mse_teste_list)\n",
        "\n",
        "    return w,mse_treino_media, mse_teste_media, mse_treino_list, mse_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ADALINE para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adaline_regression_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do ADALINE voltado para regressão.\n",
        "    Retorna os pesos finais, a média dos erros quadráticos médios de teste e treino,\n",
        "    o erro quadrático médio de treino e de teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar o MSE\n",
        "    mse_treino_list = []\n",
        "    mse_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            y_pred = np.dot(x, w)\n",
        "            erro = y_true - y_pred\n",
        "\n",
        "            # Atualizando os pesos com a regra de atualização do ADALINE\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando o MSE de treino\n",
        "        y_train_pred = np.dot(X_train, w)\n",
        "        mse_treino = np.mean((y_train - y_train_pred) ** 2)\n",
        "        mse_treino_list.append(mse_treino)\n",
        "\n",
        "        # Calculando e armazenando o MSE de teste\n",
        "        y_test_pred = np.dot(X_test, w)\n",
        "        mse_teste = np.mean((y_test - y_test_pred) ** 2)\n",
        "        mse_teste_list.append(mse_teste)\n",
        "\n",
        "    mse_treino_media = np.mean(mse_treino_list)\n",
        "    mse_teste_media = np.mean(mse_teste_list)\n",
        "\n",
        "    return w, mse_treino_media, mse_teste_media, mse_treino_list, mse_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi Layer Perceptron para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def mlp_regression_training(X_test, y_test, X_train, y_train, lr, epochs=100, hidden_neurons=10):\n",
        "    '''\n",
        "    Treinamento de um perceptron de múltiplas camadas voltado para regressão.\n",
        "    Retorna os pesos finais, o erro quadrático médio de treino e de teste por época.\n",
        "    '''\n",
        "\n",
        "    # Inicializando os pesos\n",
        "    input_neurons = X_train.shape[1]\n",
        "    output_neurons = 1  # Regressão tem uma única saída\n",
        "\n",
        "    # Pesos e bias entre camada de entrada e oculta\n",
        "    W1 = np.random.randn(input_neurons, hidden_neurons)\n",
        "    b1 = np.zeros((1, hidden_neurons))\n",
        "\n",
        "    # Pesos e bias entre camada oculta e saída\n",
        "    W2 = np.random.randn(hidden_neurons, output_neurons)\n",
        "    b2 = np.zeros((1, output_neurons))\n",
        "\n",
        "    # Listas para armazenar o MSE\n",
        "    mse_treino_list = []\n",
        "    mse_teste_list = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Forward pass\n",
        "        hidden_input = np.dot(X_train, W1) + b1\n",
        "        hidden_output = relu(hidden_input)\n",
        "\n",
        "        final_input = np.dot(hidden_output, W2) + b2\n",
        "        final_output = final_input  # Regressão linear na camada de saída\n",
        "\n",
        "        # Calculando erro\n",
        "        error = y_train - final_output\n",
        "\n",
        "        # Backward pass\n",
        "        d_output = error  # Derivada do erro na camada de saída\n",
        "        error_hidden_layer = d_output.dot(W2.T)\n",
        "        d_hidden_layer = error_hidden_layer * relu_derivative(hidden_output)\n",
        "\n",
        "        # Atualização dos pesos e bias\n",
        "        W2 += hidden_output.T.dot(d_output) * lr\n",
        "        b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "        W1 += X_train.T.dot(d_hidden_layer) * lr\n",
        "        b1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
        "\n",
        "        # Calculando o MSE de treino\n",
        "        mse_treino = np.mean(error ** 2)\n",
        "        mse_treino_list.append(mse_treino)\n",
        "\n",
        "        # Forward pass para teste\n",
        "        hidden_input_test = np.dot(X_test, W1) + b1\n",
        "        hidden_output_test = relu(hidden_input_test)\n",
        "\n",
        "        final_input_test = np.dot(hidden_output_test, W2) + b2\n",
        "        final_output_test = final_input_test\n",
        "\n",
        "        # Calculando o MSE de teste\n",
        "        mse_teste = np.mean((y_test - final_output_test) ** 2)\n",
        "        mse_teste_list.append(mse_teste)\n",
        "\n",
        "    mse_treino_media = np.mean(mse_treino_list)\n",
        "    mse_teste_media = np.mean(mse_teste_list)\n",
        "\n",
        "    return (W1, b1, W2, b2), mse_treino_media, mse_teste_media, mse_treino_list, mse_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Primeira etapa: Spiral (Classificação) e Aerogerador (Regressão)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spiral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.40724</td>\n",
              "      <td>-3.66801</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.07298</td>\n",
              "      <td>-1.56346</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-15.43986</td>\n",
              "      <td>0.16502</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9.26071</td>\n",
              "      <td>12.24981</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.59201</td>\n",
              "      <td>7.56913</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x1        x2    y\n",
              "0  15.40724  -3.66801  1.0\n",
              "1  15.07298  -1.56346  1.0\n",
              "2 -15.43986   0.16502 -1.0\n",
              "3  -9.26071  12.24981 -1.0\n",
              "4   7.59201   7.56913 -1.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Leitura do csv\n",
        "spiral_df = pd.read_csv('spiral.csv', header=None)\n",
        "\n",
        "# Mudando os nomes das colunas\n",
        "spiral_df.columns = ['x1', 'x2', 'y']\n",
        "\n",
        "# Printando as primeiras linhas\n",
        "spiral_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 15.40724,  -3.66801],\n",
              "        [ 15.07298,  -1.56346],\n",
              "        [-15.43986,   0.16502],\n",
              "        ...,\n",
              "        [ -6.41697,   5.92464],\n",
              "        [  5.00793,  -5.7493 ],\n",
              "        [  6.96596,  -6.47686]]),\n",
              " array([ 1.,  1., -1., ...,  1., -1., -1.]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Separando as features e os targets\n",
        "X = spiral_df[['x1', 'x2']].values\n",
        "\n",
        "y = spiral_df['y'].values\n",
        "\n",
        "X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setando o número de rodadas, número de épocas e taxa de aprendizado\n",
        "n_rounds = 100\n",
        "n_epochs = 10\n",
        "lr = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valores que receberemos ao final do treino: pesos finais, acurácia média de treino e teste, e listas de acurácia\n",
        "# Valores que iremos gerar apos o final das rodaas para teste e treino: acurácia média, mediana, mínimo, máximo e desvio padrão\n",
        "\n",
        "# Inicializando as listas para armazenar os resultados para cada modelo\n",
        "perceptron_acc_treino_list = []\n",
        "perceptron_acc_test_list = []\n",
        "\n",
        "adaline_acc_treino_list = []\n",
        "adaline_acc_test_list = []\n",
        "\n",
        "mlp_acc_treino_list = []\n",
        "mlp_acc_test_list = []\n",
        "\n",
        "\n",
        "\n",
        "for i in n_rounds:\n",
        "    # Separando os dados de treino e teste\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Normalizando os dados\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Treinando o perceptron simples\n",
        "    w_perceptron, acc_treino_perceptron, acc_teste_perceptron, _, _ = perceptron_simples_classification_training(X_test, y_test, X_train, y_train, lr, epochs=n_epochs)\n",
        "    perceptron_acc_treino_list.append(acc_treino_perceptron)\n",
        "    perceptron_acc_test_list.append(acc_teste_perceptron)\n",
        "\n",
        "    # Treinando o ADALINE\n",
        "    w_adaline, acc_treino_adaline, acc_teste_adaline, _, _ = adaline_classification_training(X_test, y_test, X_train, y_train, lr, epochs=n_epochs)\n",
        "    adaline_acc_treino_list.append(acc_treino_adaline)\n",
        "    adaline_acc_test_list.append(acc_teste_adaline)\n",
        "\n",
        "    # Treinando o MLP\n",
        "    pesos_mlp, acc_treino_mlp, acc_teste_mlp, _, _ = mlp_classification_training(X_test, y_test, X_train, y_train, lr, epochs=n_epochs)\n",
        "    mlp_acc_treino_list.append(acc_treino_mlp)\n",
        "    mlp_acc_test_list.append(acc_teste_mlp)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
