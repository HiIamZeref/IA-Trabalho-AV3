{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEhkPKsMkH77"
      },
      "source": [
        "## Imports principais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YOyBeEB4kHeE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMtVFAr9hmCI"
      },
      "source": [
        "## Implementação dos modelos para classificação\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT3ddKynmSGT"
      },
      "source": [
        "### Perceptron simples classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IR6AAwY5mU_-",
        "outputId": "c2beff1f-a98d-418c-9d19-cd92d5bc5b25"
      },
      "outputs": [],
      "source": [
        "def perceptron_simples_classification_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do perceptron simples voltado para classificação.\n",
        "    Retorna os pesos finais, a acurácia de treino média, a acurácia de teste média, \n",
        "    e as listas de acurácia de treino e teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar a acurácia\n",
        "    acuracia_treino_list = []\n",
        "    acuracia_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        acertos_treino = 0\n",
        "\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            erro = y_true - y_pred\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_treino += 1\n",
        "\n",
        "            # Atualizando os pesos\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando a acurácia de treino\n",
        "        acuracia_treino = acertos_treino / len(X_train)\n",
        "        acuracia_treino_list.append(acuracia_treino)\n",
        "\n",
        "        # Fase de teste\n",
        "        acertos_teste = 0\n",
        "        for x, y_true in zip(X_test, y_test):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_teste += 1\n",
        "\n",
        "        # Calculando e armazenando a acurácia de teste\n",
        "        acuracia_teste = acertos_teste / len(X_test)\n",
        "        acuracia_teste_list.append(acuracia_teste)\n",
        "\n",
        "    # Calculando a acurácia média de treino e teste\n",
        "    acuracia_treino_media = np.mean(acuracia_treino_list)\n",
        "    acuracia_teste_media = np.mean(acuracia_teste_list)\n",
        "\n",
        "    return w, acuracia_treino_media, acuracia_teste_media, acuracia_treino_list, acuracia_teste_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i45l-ZI3KWQg"
      },
      "source": [
        "### ADALINE classificação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ3lLcnLKbOl",
        "outputId": "6773c24a-a92a-4df8-c1d9-cdd03c8099d0"
      },
      "outputs": [],
      "source": [
        "def adaline_classification_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do ADALINE voltado para classificação.\n",
        "    Retorna os pesos finais, a acurácia de treino média, a acurácia de teste média,\n",
        "    e as listas de acurácia de treino e teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar a acurácia\n",
        "    acuracia_treino_list = []\n",
        "    acuracia_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        acertos_treino = 0\n",
        "\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            erro = y_true - u\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_treino += 1\n",
        "\n",
        "            # Atualizando os pesos com a regra de atualização do ADALINE\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando a acurácia de treino\n",
        "        acuracia_treino = acertos_treino / len(X_train)\n",
        "        acuracia_treino_list.append(acuracia_treino)\n",
        "\n",
        "        # Fase de teste\n",
        "        acertos_teste = 0\n",
        "        for x, y_true in zip(X_test, y_test):\n",
        "            u = np.dot(x, w)\n",
        "            y_pred = np.sign(u)\n",
        "\n",
        "            if y_true == y_pred:\n",
        "                acertos_teste += 1\n",
        "\n",
        "        # Calculando e armazenando a acurácia de teste\n",
        "        acuracia_teste = acertos_teste / len(X_test)\n",
        "        acuracia_teste_list.append(acuracia_teste)\n",
        "\n",
        "    # Calculando a acurácia média de treino e teste\n",
        "    acuracia_treino_media = np.mean(acuracia_treino_list)\n",
        "    acuracia_teste_media = np.mean(acuracia_teste_list)\n",
        "\n",
        "    return w, acuracia_treino_media, acuracia_teste_media, acuracia_treino_list, acuracia_teste_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGDnoZERwcq8"
      },
      "source": [
        "### Perceptron de múltiplas camadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq-Er75bwb6M",
        "outputId": "16dd9925-c126-432d-a920-b9f7866b0c8d"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def mlp_classification_training(X_test,\n",
        "                                y_test,\n",
        "                                X_train,\n",
        "                                y_train, \n",
        "                                lr, \n",
        "                                epochs=100, \n",
        "                                hidden_neurons=8):\n",
        "    '''\n",
        "    Treinamento de um perceptron de múltiplas camadas voltado para classificação.\n",
        "    Retorna os pesos finais, a acurácia de treino média, a acurácia de teste média,\n",
        "    e as listas de acurácia de treino e teste por época.\n",
        "    '''\n",
        "\n",
        "    # Inicializando os pesos\n",
        "    input_neurons = X_train.shape[1]\n",
        "    output_neurons = len(np.unique(y_train))  # Número de classes\n",
        "\n",
        "    # Pesos e bias entre camada de entrada e oculta\n",
        "    W1 = np.random.randn(input_neurons, hidden_neurons)\n",
        "    b1 = np.zeros((1, hidden_neurons))\n",
        "\n",
        "    # Pesos e bias entre camada oculta e saída\n",
        "    W2 = np.random.randn(hidden_neurons, output_neurons)\n",
        "    b2 = np.zeros((1, output_neurons))\n",
        "\n",
        "    # Listas para armazenar a acurácia\n",
        "    acuracia_treino_list = []\n",
        "    acuracia_teste_list = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Forward pass\n",
        "        hidden_input = np.dot(X_train, W1) + b1\n",
        "        hidden_output = relu(hidden_input)\n",
        "\n",
        "        final_input = np.dot(hidden_output, W2) + b2\n",
        "        final_output = sigmoid(final_input)\n",
        "\n",
        "        # Calculando erro\n",
        "        y_train_one_hot = np.eye(output_neurons)[y_train]  # Convertendo para one-hot encoding\n",
        "        error = y_train_one_hot - final_output\n",
        "\n",
        "        # Backward pass\n",
        "        d_output = error * sigmoid_derivative(final_output)\n",
        "        error_hidden_layer = d_output.dot(W2.T)\n",
        "        d_hidden_layer = error_hidden_layer * relu_derivative(hidden_output)\n",
        "\n",
        "        # Atualização dos pesos e bias\n",
        "        W2 += hidden_output.T.dot(d_output) * lr\n",
        "        b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "        W1 += X_train.T.dot(d_hidden_layer) * lr\n",
        "        b1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
        "\n",
        "        # Calculando acurácia de treino\n",
        "        train_predictions = np.argmax(final_output, axis=1)\n",
        "        acertos_treino = np.sum(train_predictions == y_train)\n",
        "        acuracia_treino = acertos_treino / len(y_train)\n",
        "        acuracia_treino_list.append(acuracia_treino)\n",
        "\n",
        "        # Forward pass para teste\n",
        "        hidden_input_test = np.dot(X_test, W1) + b1\n",
        "        hidden_output_test = relu(hidden_input_test)\n",
        "\n",
        "        final_input_test = np.dot(hidden_output_test, W2) + b2\n",
        "        final_output_test = sigmoid(final_input_test)\n",
        "\n",
        "        # Calculando acurácia de teste\n",
        "        test_predictions = np.argmax(final_output_test, axis=1)\n",
        "        acertos_teste = np.sum(test_predictions == y_test)\n",
        "        acuracia_teste = acertos_teste / len(y_test)\n",
        "        acuracia_teste_list.append(acuracia_teste)\n",
        "\n",
        "    # Calculando a acurácia média de treino e teste\n",
        "    acuracia_treino_media = np.mean(acuracia_treino_list)\n",
        "    acuracia_teste_media = np.mean(acuracia_teste_list)\n",
        "\n",
        "    return (W1, b1, W2, b2), acuracia_treino_media, acuracia_teste_media, acuracia_treino_list, acuracia_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EBTJ4VN0JIk"
      },
      "source": [
        "## Implementação modelos regressão\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OLxHHjKUHqL"
      },
      "source": [
        "### Perceptron Simples para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMSU7mHz0Mnj",
        "outputId": "ae939e4f-d9ac-4b50-807d-4fb380043cf7"
      },
      "outputs": [],
      "source": [
        "def perceptron_simples_regression_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do perceptron simples voltado para regressão.\n",
        "    Retorna os pesos finais, o erro quadrático médio de treino e de teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar o MSE\n",
        "    mse_treino_list = []\n",
        "    mse_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            y_pred = np.dot(x, w)\n",
        "            erro = y_true - y_pred\n",
        "\n",
        "            # Atualizando os pesos\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando o MSE de treino\n",
        "        y_train_pred = np.dot(X_train, w)\n",
        "        mse_treino = np.mean((y_train - y_train_pred) ** 2)\n",
        "        mse_treino_list.append(mse_treino)\n",
        "\n",
        "        # Calculando e armazenando o MSE de teste\n",
        "        y_test_pred = np.dot(X_test, w)\n",
        "        mse_teste = np.mean((y_test - y_test_pred) ** 2)\n",
        "        mse_teste_list.append(mse_teste)\n",
        "\n",
        "    mse_treino_media = np.mean(mse_treino_list)\n",
        "    mse_teste_media = np.mean(mse_teste_list)\n",
        "\n",
        "    return w,mse_treino_media, mse_teste_media, mse_treino_list, mse_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ADALINE para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adaline_regression_training(X_test, y_test, X_train, y_train, lr, epochs=100):\n",
        "    '''\n",
        "    Treinamento do ADALINE voltado para regressão.\n",
        "    Retorna os pesos finais, a média dos erros quadráticos médios de teste e treino,\n",
        "    o erro quadrático médio de treino e de teste por época.\n",
        "    '''\n",
        "\n",
        "    # Instanciando as listas para armazenar o MSE\n",
        "    mse_treino_list = []\n",
        "    mse_teste_list = []\n",
        "\n",
        "    # Instanciando pesos\n",
        "    w = np.zeros(X_train.shape[1])\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Fase de treinamento\n",
        "        for x, y_true in zip(X_train, y_train):\n",
        "            y_pred = np.dot(x, w)\n",
        "            erro = y_true - y_pred\n",
        "\n",
        "            # Atualizando os pesos com a regra de atualização do ADALINE\n",
        "            w += lr * erro * x\n",
        "\n",
        "        # Calculando e armazenando o MSE de treino\n",
        "        y_train_pred = np.dot(X_train, w)\n",
        "        mse_treino = np.mean((y_train - y_train_pred) ** 2)\n",
        "        mse_treino_list.append(mse_treino)\n",
        "\n",
        "        # Calculando e armazenando o MSE de teste\n",
        "        y_test_pred = np.dot(X_test, w)\n",
        "        mse_teste = np.mean((y_test - y_test_pred) ** 2)\n",
        "        mse_teste_list.append(mse_teste)\n",
        "\n",
        "    mse_treino_media = np.mean(mse_treino_list)\n",
        "    mse_teste_media = np.mean(mse_teste_list)\n",
        "\n",
        "    return w, mse_treino_media, mse_teste_media, mse_treino_list, mse_teste_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multi Layer Perceptron para Regressão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def mlp_regression_training(X_test, y_test, X_train, y_train, lr, epochs=100, hidden_neurons=10):\n",
        "    '''\n",
        "    Treinamento de um perceptron de múltiplas camadas voltado para regressão.\n",
        "    Retorna os pesos finais, o erro quadrático médio de treino e de teste por época.\n",
        "    '''\n",
        "\n",
        "    # Inicializando os pesos\n",
        "    input_neurons = X_train.shape[1]\n",
        "    output_neurons = 1  # Regressão tem uma única saída\n",
        "\n",
        "    # Pesos e bias entre camada de entrada e oculta\n",
        "    W1 = np.random.randn(input_neurons, hidden_neurons)\n",
        "    b1 = np.zeros((1, hidden_neurons))\n",
        "\n",
        "    # Pesos e bias entre camada oculta e saída\n",
        "    W2 = np.random.randn(hidden_neurons, output_neurons)\n",
        "    b2 = np.zeros((1, output_neurons))\n",
        "\n",
        "    # Listas para armazenar o MSE\n",
        "    mse_treino_list = []\n",
        "    mse_teste_list = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # Forward pass\n",
        "        hidden_input = np.dot(X_train, W1) + b1\n",
        "        hidden_output = relu(hidden_input)\n",
        "\n",
        "        final_input = np.dot(hidden_output, W2) + b2\n",
        "        final_output = final_input  # Regressão linear na camada de saída\n",
        "\n",
        "        # Calculando erro\n",
        "        error = y_train - final_output\n",
        "\n",
        "        # Backward pass\n",
        "        d_output = error  # Derivada do erro na camada de saída\n",
        "        error_hidden_layer = d_output.dot(W2.T)\n",
        "        d_hidden_layer = error_hidden_layer * relu_derivative(hidden_output)\n",
        "\n",
        "        # Atualização dos pesos e bias\n",
        "        W2 += hidden_output.T.dot(d_output) * lr\n",
        "        b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n",
        "        W1 += X_train.T.dot(d_hidden_layer) * lr\n",
        "        b1 += np.sum(d_hidden_layer, axis=0, keepdims=True) * lr\n",
        "\n",
        "        # Calculando o MSE de treino\n",
        "        mse_treino = np.mean(error ** 2)\n",
        "        mse_treino_list.append(mse_treino)\n",
        "\n",
        "        # Forward pass para teste\n",
        "        hidden_input_test = np.dot(X_test, W1) + b1\n",
        "        hidden_output_test = relu(hidden_input_test)\n",
        "\n",
        "        final_input_test = np.dot(hidden_output_test, W2) + b2\n",
        "        final_output_test = final_input_test\n",
        "\n",
        "        # Calculando o MSE de teste\n",
        "        mse_teste = np.mean((y_test - final_output_test) ** 2)\n",
        "        mse_teste_list.append(mse_teste)\n",
        "\n",
        "    mse_treino_media = np.mean(mse_treino_list)\n",
        "    mse_teste_media = np.mean(mse_teste_list)\n",
        "\n",
        "    return (W1, b1, W2, b2), mse_treino_media, mse_teste_media, mse_treino_list, mse_teste_list\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
